FROM nvidia/cuda:12.6.0-devel-ubuntu22.04

# Install system dependencies
RUN apt-get update && apt-get install --no-install-recommends -y \
    git vim build-essential python3-dev python3-venv python3-pip cmake \
    curl wget ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Set up Python environment
ENV VIRTUAL_ENV=/venv
RUN python3 -m venv $VIRTUAL_ENV
ENV PATH="$VIRTUAL_ENV/bin:$PATH"

# Install PyTorch and basic dependencies for CUDA 12.6
RUN pip3 install --upgrade pip setuptools wheel
RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Clone text-generation-webui
WORKDIR /app
RUN git clone https://github.com/oobabooga/text-generation-webui.git .

# Install text-generation-webui dependencies
RUN pip3 install -r requirements.txt || echo "Some requirements failed, continuing..."

# Install additional dependencies for OpenAI API compatibility and GPU support
RUN pip3 install gradio transformers accelerate bitsandbytes scipy tiktoken matplotlib \
    numpy pandas requests flask fastapi uvicorn pydantic markdown pillow sse-starlette \
    websockets aiofiles jinja2

# Install llama-cpp-python with CUDA support
RUN CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip3 install llama-cpp-python --upgrade --force-reinstall --no-cache-dir || \
    pip3 install llama-cpp-python --upgrade --no-cache-dir || \
    echo "llama-cpp-python installation failed, continuing..."

# Create necessary directories
RUN mkdir -p /app/models /app/loras /app/presets /app/prompts /app/training /app/extensions

# Expose ports
EXPOSE 7860 5000 5005 5001

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV EXTRA_LAUNCH_ARGS=""

# Copy scripts
COPY ./scripts /scripts
RUN chmod +x /scripts/* || echo "No scripts directory found"

# Default command
CMD ["python3", "server.py", "--listen", "--verbose", "--extensions", "openai"]
